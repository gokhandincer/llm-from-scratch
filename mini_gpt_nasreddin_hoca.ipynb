{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§  Mini GPT: SÄ±fÄ±rdan Decoder-Only Transformer\n",
    "\n",
    "Bu notebook'ta sÄ±fÄ±rdan bir GPT-style dil modeli oluÅŸturacaÄŸÄ±z ve **Nasreddin Hoca fÄ±kralarÄ±yla** eÄŸiteceÄŸiz!\n",
    "\n",
    "## Ä°Ã§indekiler\n",
    "\n",
    "1. [Kurulum ve Veri HazÄ±rlama](#1-kurulum-ve-veri-hazÄ±rlama)\n",
    "2. [Tokenizer](#2-tokenizer)\n",
    "3. [Model Mimarisi](#3-model-mimarisi)\n",
    "4. [EÄŸitim](#4-eÄŸitim)\n",
    "5. [Metin Ãœretimi](#5-metin-Ã¼retimi)\n",
    "6. [SonuÃ§lar ve Analiz](#6-sonuÃ§lar-ve-analiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Kurulum ve Veri HazÄ±rlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ KullanÄ±lan cihaz: cuda\n",
      "ğŸ“¦ PyTorch versiyon: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ–¥ï¸ KullanÄ±lan cihaz: {device}\")\n",
    "print(f\"ğŸ“¦ PyTorch versiyon: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š Nasreddin Hoca FÄ±kralarÄ±\n",
    "\n",
    "Mini bir dataset oluÅŸturuyoruz. GerÃ§ek uygulamada daha fazla veri kullanÄ±lmalÄ±!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– Corpus uzunluÄŸu: 5,339 karakter\n",
      "ğŸ“– Unique karakterler: 56\n",
      "\n",
      "ğŸ“ Ä°lk 500 karakter:\n",
      "\n",
      "Nasreddin Hoca bir gÃ¼n eÅŸeÄŸine ters binmiÅŸ. GÃ¶renler sormuÅŸ: \"Hoca, neden ters bindin?\" Hoca cevap vermiÅŸ: \"Ben ters binmedim, eÅŸek ters duruyor.\"\n",
      "\n",
      "Bir gÃ¼n Nasreddin Hoca gÃ¶le maya Ã§alÄ±yormuÅŸ. GÃ¶renler sormuÅŸ: \"Hoca ne yapÄ±yorsun?\" Hoca: \"GÃ¶le maya Ã§alÄ±yorum, belki tutarda yoÄŸurt olur.\" demis. \"HiÃ§ gÃ¶lden yoÄŸurt olur mu?\" demiÅŸler. Hoca: \"Ya tutarsa?\" demiÅŸ.\n",
      "\n",
      "Nasreddin Hoca kaybettiÄŸi anahtarÄ± sokak lambasÄ±nÄ±n altÄ±nda arÄ±yormuÅŸ. Biri sormuÅŸ: \"Hoca anahtarÄ± nerede kaybettin?\" Hoca: \"Evde kaybett\n"
     ]
    }
   ],
   "source": [
    "# Nasreddin Hoca fÄ±kralarÄ± corpus'u\n",
    "nasreddin_corpus = '''\n",
    "Nasreddin Hoca bir gÃ¼n eÅŸeÄŸine ters binmiÅŸ. GÃ¶renler sormuÅŸ: \"Hoca, neden ters bindin?\" Hoca cevap vermiÅŸ: \"Ben ters binmedim, eÅŸek ters duruyor.\"\n",
    "\n",
    "Bir gÃ¼n Nasreddin Hoca gÃ¶le maya Ã§alÄ±yormuÅŸ. GÃ¶renler sormuÅŸ: \"Hoca ne yapÄ±yorsun?\" Hoca: \"GÃ¶le maya Ã§alÄ±yorum, belki tutarda yoÄŸurt olur.\" demis. \"HiÃ§ gÃ¶lden yoÄŸurt olur mu?\" demiÅŸler. Hoca: \"Ya tutarsa?\" demiÅŸ.\n",
    "\n",
    "Nasreddin Hoca kaybettiÄŸi anahtarÄ± sokak lambasÄ±nÄ±n altÄ±nda arÄ±yormuÅŸ. Biri sormuÅŸ: \"Hoca anahtarÄ± nerede kaybettin?\" Hoca: \"Evde kaybettim.\" demiÅŸ. \"Peki neden burada arÄ±yorsun?\" diye sorunca Hoca: \"BurasÄ± daha aydÄ±nlÄ±k da ondan.\" demiÅŸ.\n",
    "\n",
    "Hoca bir gÃ¼n pazara gitmiÅŸ. SatÄ±cÄ± sormuÅŸ: \"Hoca bu kabaÄŸÄ± kaÃ§a alÄ±rsÄ±n?\" Hoca: \"BeÅŸ akÃ§eye alÄ±rÄ±m.\" demiÅŸ. SatÄ±cÄ±: \"On akÃ§e ister.\" demiÅŸ. Hoca dÃ¼ÅŸÃ¼nmÃ¼ÅŸ ve demiÅŸ ki: \"Ben beÅŸ akÃ§eye almam diyorum, sen on akÃ§eye vermem diyorsun. Ã–yleyse ikimiz de almayalÄ±m.\"\n",
    "\n",
    "Nasreddin Hoca komÅŸusundan kazan Ã¶dÃ¼nÃ§ almÄ±ÅŸ. Bir sÃ¼re sonra kazanÄ± geri verirken iÃ§ine kÃ¼Ã§Ã¼k bir tencere koymuÅŸ. KomÅŸusu sormuÅŸ: \"Bu tencere ne Hoca?\" Hoca: \"Kazan doÄŸurdu.\" demiÅŸ. KomÅŸusu sevinerek almÄ±ÅŸ. Bir sÃ¼re sonra Hoca yine kazan istemiÅŸ ama geri vermemiÅŸ. KomÅŸusu sorunca Hoca: \"Kazan Ã¶ldÃ¼.\" demiÅŸ. KomÅŸusu itiraz edince Hoca: \"DoÄŸurduÄŸuna inandÄ±n da Ã¶ldÃ¼ÄŸÃ¼ne niye inanmÄ±yorsun?\" demiÅŸ.\n",
    "\n",
    "Bir gÃ¼n Hoca hamama gitmiÅŸ. HamamcÄ± ona eski bir havlu ve kÃ¼Ã§Ã¼k bir sabun vermiÅŸ. Hoca Ã§Ä±karken bol bahÅŸiÅŸ vermiÅŸ. Bir hafta sonra yine gitmiÅŸ. Bu sefer hamamcÄ± en iyi havluyu ve en gÃ¼zel sabunu vermiÅŸ. Ama Hoca bu sefer hiÃ§ bahÅŸiÅŸ vermemiÅŸ. HamamcÄ± sormuÅŸ: \"GeÃ§en sefer az hizmet Ã§ok bahÅŸiÅŸ, bu sefer Ã§ok hizmet hiÃ§ bahÅŸiÅŸ. Neden Hoca?\" Hoca gÃ¼lmÃ¼ÅŸ: \"Bu seferki bahÅŸiÅŸ geÃ§en seferki hizmetin karÅŸÄ±lÄ±ÄŸÄ±, geÃ§en seferki bahÅŸiÅŸ de bu seferki hizmetin karÅŸÄ±lÄ±ÄŸÄ±ydÄ±.\"\n",
    "\n",
    "Hoca bir gÃ¼n yolda yÃ¼rÃ¼rken bir adam koÅŸarak gelmiÅŸ ve sormuÅŸ: \"Hoca, cenaze nereye gidiyor?\" Hoca tabutun Ã¼zerindeki kiÅŸiye bakmÄ±ÅŸ ve demiÅŸ: \"EÄŸer mezarlÄ±ÄŸa gidiyorsa oraya, eve gidiyorsa eve.\"\n",
    "\n",
    "Nasreddin Hoca minareden dÃ¼ÅŸmÃ¼ÅŸ. Halk etrafÄ±na toplanmÄ±ÅŸ. Biri sormuÅŸ: \"Hoca, dÃ¼ÅŸmek nasÄ±l bir ÅŸey?\" Hoca inleyerek cevap vermiÅŸ: \"DÃ¼ÅŸmek bir ÅŸey deÄŸil, asÄ±l yere Ã§arpmak zor.\"\n",
    "\n",
    "Bir gÃ¼n Hoca eÅŸeÄŸini kaybetmiÅŸ. Her yerde aramÄ±ÅŸ bulamamÄ±ÅŸ. Sonunda gÃ¶zleri dolarak dua etmeye baÅŸlamÄ±ÅŸ: \"Ya Rabbi! EÅŸeÄŸimi buldur. Bulduran kiÅŸiye eÅŸeÄŸi vereceÄŸim.\" YanÄ±ndakiler sormuÅŸ: \"Hoca, eÅŸeÄŸi bulana verirsen sana ne kalÄ±r?\" Hoca: \"HiÃ§ olmazsa bulmanÄ±n sevabÄ± kalÄ±r.\" demiÅŸ.\n",
    "\n",
    "Hoca sarÄ±ÄŸÄ±nÄ± Ã§almÄ±ÅŸlar. Ertesi gÃ¼n camide vaaz verirken demiÅŸ ki: \"Ey cemaat! DÃ¼n gece sarÄ±ÄŸÄ±mÄ± Ã§aldÄ±lar. Bilen varsa sÃ¶ylesin.\" Cemaatten biri sormuÅŸ: \"Hoca, sarÄ±ÄŸÄ± Ã§alan burada mÄ± ki?\" Hoca cevap vermiÅŸ: \"Bilmem, ama sarÄ±ÄŸÄ± Ã§alan burada deÄŸilse bile sarÄ±ÄŸÄ±m burada olabilir.\"\n",
    "\n",
    "Nasreddin Hoca bir gÃ¼n Ã§arÅŸÄ±da gezerken birisi ona bir tokat atmÄ±ÅŸ. Hoca adama bakmÄ±ÅŸ ve demiÅŸ: \"Ã–zÃ¼r dilerim, sizi tanÄ±yamadÄ±m.\" Adam ÅŸaÅŸÄ±rmÄ±ÅŸ: \"Ben sana tokat attÄ±m, sen neden Ã¶zÃ¼r diliyorsun?\" Hoca: \"Ã‡Ã¼nkÃ¼ siz beni baÅŸka biriyle karÄ±ÅŸtÄ±rdÄ±nÄ±z, yoksa bana tokat atmazdÄ±nÄ±z.\" demiÅŸ.\n",
    "\n",
    "Bir gÃ¼n HocanÄ±n evine hÄ±rsÄ±z girmiÅŸ. Hoca uyanmÄ±ÅŸ ama sesini Ã§Ä±karmamÄ±ÅŸ. HÄ±rsÄ±z her yeri aramÄ±ÅŸ ama bir ÅŸey bulamamÄ±ÅŸ. Tam giderken Hoca arkasÄ±ndan seslenmiÅŸ: \"EvladÄ±m, biz bu evde otuz yÄ±ldÄ±r bir ÅŸey bulamadÄ±k, sen bir gecede ne bulacaksÄ±n?\"\n",
    "\n",
    "Hoca bir gÃ¼n aÄŸaca Ã§Ä±kmÄ±ÅŸ. DallarÄ± keserken oturduÄŸu dalÄ± kesmeye baÅŸlamÄ±ÅŸ. Yoldan geÃ§en biri baÄŸÄ±rmÄ±ÅŸ: \"Hoca, oturduÄŸun dalÄ± kesme, dÃ¼ÅŸersin!\" Hoca dinlememiÅŸ, dalÄ± kesmeye devam etmiÅŸ ve dÃ¼ÅŸmÃ¼ÅŸ. KalkmÄ±ÅŸ, adamÄ±n peÅŸinden koÅŸmuÅŸ: \"Sen gelecekten haber mi alÄ±yorsun? Benim ne zaman Ã¶leceÄŸimi de sÃ¶yle.\" Adam: \"Bilemem Hoca.\" demiÅŸ. Hoca: \"EÅŸeÄŸin kÄ±rk kere anÄ±rÄ±rsa Ã¶lÃ¼rsÃ¼n.\" demiÅŸ ve gitmiÅŸ. Adam korkuyla eÅŸeÄŸini saymaya baÅŸlamÄ±ÅŸ.\n",
    "\n",
    "Nasreddin Hoca bir gÃ¼n yolda giderken karÅŸÄ±sÄ±na bir adam Ã§Ä±kmÄ±ÅŸ ve hiÃ§ tanÄ±madÄ±ÄŸÄ± halde tokadÄ± yapÄ±ÅŸtÄ±rmÄ±ÅŸ. Hoca ÅŸaÅŸkÄ±nlÄ±kla adama bakmÄ±ÅŸ. Adam Ã¶zÃ¼r dilemiÅŸ: \"Ã‡ok Ã¶zÃ¼r dilerim, seni arkadaÅŸÄ±ma benzettim.\" Hoca dÃ¼ÅŸÃ¼nmÃ¼ÅŸ ve demiÅŸ: \"ArkadaÅŸÄ±n da senin gibi densiz biri olmalÄ±.\"\n",
    "\n",
    "Bir gÃ¼n Hoca evinde otururken kapÄ± Ã§alÄ±nmÄ±ÅŸ. KarÄ±sÄ± aÃ§mÄ±ÅŸ, dilenci ekmek istiyormuÅŸ. KarÄ±sÄ± yukarÄ± Ã§Ä±kÄ±p Hocaya sormuÅŸ: \"KapÄ±da dilenci var, ekmek istiyor.\" Hoca: \"SÃ¶yle aÅŸaÄŸÄ± insin.\" demiÅŸ. Dilenci aÅŸaÄŸÄ± inmiÅŸ. Hoca yine: \"SÃ¶yle biraz daha aÅŸaÄŸÄ± insin.\" demiÅŸ. Dilenci mahzene inmiÅŸ. Hoca: \"Åimdi sÃ¶yle, bu evde ekmek yok.\" demiÅŸ.\n",
    "\n",
    "Hoca pazarda koyun satÄ±yormuÅŸ. Bir mÃ¼ÅŸteri gelmiÅŸ: \"Bu koyunun sÃ¼tÃ¼ Ã§ok mu?\" Hoca: \"O kadar Ã§ok ki, sabah saÄŸarsÄ±n akÅŸama kadar sÃ¼t verir.\" demiÅŸ. MÃ¼ÅŸteri almÄ±ÅŸ. Ertesi gÃ¼n gelmiÅŸ: \"Hoca bu koyundan sÃ¼t Ã§Ä±kmÄ±yor.\" Hoca sakin sakin cevap vermiÅŸ: \"Ben sana sÃ¼t verir dedim, sen saÄŸmasÄ±nÄ± bilmiyorsun.\"\n",
    "\n",
    "Nasreddin Hoca yolda giderken bir adam sormuÅŸ: \"Hoca, ÅŸu kÃ¶ye gitmek iÃ§in ne kadar yÃ¼rÃ¼mem lazÄ±m?\" Hoca cevap vermemiÅŸ ve yÃ¼rÃ¼meye devam etmiÅŸ. Adam biraz yÃ¼rÃ¼yÃ¼nce Hoca arkasÄ±ndan seslenmiÅŸ: \"YarÄ±m saat kadar.\" Adam dÃ¶nmÃ¼ÅŸ: \"Bunu neden hemen sÃ¶ylemedin?\" Hoca: \"NasÄ±l yÃ¼rÃ¼dÃ¼ÄŸÃ¼nÃ¼ bilmeden nasÄ±l sÃ¶yleyeyim?\" demiÅŸ.\n",
    "\n",
    "Hoca bir gÃ¼n damdan dÃ¼ÅŸmÃ¼ÅŸ. Ahali toplanmÄ±ÅŸ, biri sormuÅŸ: \"Hoca damdan dÃ¼ÅŸmek nasÄ±l bir his?\" Hoca inleyerek: \"Bilmiyorum, daha Ã¶nce hiÃ§ dÃ¼ÅŸmemiÅŸtim.\" demiÅŸ.\n",
    "\n",
    "Bir gÃ¼n Hocaya sormuÅŸlar: \"DÃ¼nyanÄ±n merkezi neresidir?\" Hoca ayaÄŸÄ±yla yeri gÃ¶stermiÅŸ: \"Ä°ÅŸte burasÄ±dÄ±r.\" demis. \"Nereden biliyorsun?\" diye sorunca: \"Ä°nanmazsanÄ±z Ã¶lÃ§Ã¼n.\" demiÅŸ.\n",
    "\n",
    "Nasreddin Hoca bir gece evine hÄ±rsÄ±z girdiÄŸini duymuÅŸ. KarÄ±sÄ±na: \"Ses Ã§Ä±karma, hÄ±rsÄ±z ne bulursa alsÄ±n, belki biz de ondan bir ÅŸeyler kapabiliriz.\" demiÅŸ.\n",
    "'''\n",
    "\n",
    "print(f\"ğŸ“– Corpus uzunluÄŸu: {len(nasreddin_corpus):,} karakter\")\n",
    "print(f\"ğŸ“– Unique karakterler: {len(set(nasreddin_corpus))}\")\n",
    "print(f\"\\nğŸ“ Ä°lk 500 karakter:\\n{nasreddin_corpus[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Tokenizer\n",
    "\n",
    "Basitlik iÃ§in **karakter seviyesi** (character-level) tokenization kullanacaÄŸÄ±z.\n",
    "\n",
    "GerÃ§ek GPT modelleri BPE (Byte Pair Encoding) kullanÄ±r, ama bu eÄŸitim iÃ§in char-level yeterli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Vocab boyutu: 56\n",
      "\n",
      "ğŸ”¤ Karakterler: \n",
      " !\",.:?ABCDEGHKMNOPRSTYabcdefghiklmnoprstuvyzÃ‡Ã–Ã§Ã¶...\n",
      "\n",
      "âœ… Test:\n",
      "   Orijinal: Nasreddin Hoca\n",
      "   Encoded:  [17, 24, 40, 39, 28, 27, 27, 32, 36, 1, 14, 37, 26, 24]\n",
      "   Decoded:  Nasreddin Hoca\n"
     ]
    }
   ],
   "source": [
    "class CharTokenizer:\n",
    "    \"\"\"\n",
    "    Karakter seviyesi tokenizer.\n",
    "    \n",
    "    Her unique karakter bir token'a karÅŸÄ±lÄ±k gelir.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        # Unique karakterleri bul ve sÄ±rala\n",
    "        self.chars = sorted(list(set(text)))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        \n",
    "        # Karakter <-> ID mapping\n",
    "        self.char_to_id = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.id_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        \"\"\"Metni token ID listesine Ã§evir\"\"\"\n",
    "        return [self.char_to_id[ch] for ch in text]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        \"\"\"Token ID listesini metne Ã§evir\"\"\"\n",
    "        return ''.join([self.id_to_char[i] for i in ids])\n",
    "\n",
    "# Tokenizer oluÅŸtur\n",
    "tokenizer = CharTokenizer(nasreddin_corpus)\n",
    "\n",
    "print(f\"ğŸ“Š Vocab boyutu: {tokenizer.vocab_size}\")\n",
    "print(f\"\\nğŸ”¤ Karakterler: {''.join(tokenizer.chars[:50])}...\")\n",
    "print(f\"\\nâœ… Test:\")\n",
    "test_text = \"Nasreddin Hoca\"\n",
    "encoded = tokenizer.encode(test_text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"   Orijinal: {test_text}\")\n",
    "print(f\"   Encoded:  {encoded}\")\n",
    "print(f\"   Decoded:  {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“¦ Dataset SÄ±nÄ±fÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dataset boyutu: 5,211 Ã¶rnek\n",
      "ğŸ“Š Batch sayÄ±sÄ±: 163\n",
      "\n",
      "ğŸ“¦ Ã–rnek batch:\n",
      "   x shape: torch.Size([32, 128])\n",
      "   y shape: torch.Size([32, 128])\n",
      "\n",
      "   Ä°lk Ã¶rnek (ilk 50 karakter):\n",
      "   Input:  'zan Ã¶dÃ¼nÃ§ almÄ±ÅŸ. Bir sÃ¼re sonra kazanÄ± geri verirk'\n",
      "   Target: 'an Ã¶dÃ¼nÃ§ almÄ±ÅŸ. Bir sÃ¼re sonra kazanÄ± geri verirke'\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dil modelleme iÃ§in dataset.\n",
    "    \n",
    "    Her Ã¶rnek:\n",
    "    - input: [t0, t1, t2, ..., tn-1]\n",
    "    - target: [t1, t2, t3, ..., tn] (bir kaydÄ±rÄ±lmÄ±ÅŸ)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text, tokenizer, seq_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # TÃ¼m metni tokenize et\n",
    "        self.data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Her baÅŸlangÄ±Ã§ pozisyonu bir Ã¶rnek\n",
    "        return len(self.data) - self.seq_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Input: [idx : idx + seq_len]\n",
    "        # Target: [idx + 1 : idx + seq_len + 1]\n",
    "        x = self.data[idx : idx + self.seq_len]\n",
    "        y = self.data[idx + 1 : idx + self.seq_len + 1]\n",
    "        return x, y\n",
    "\n",
    "# Dataset ve DataLoader\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = TextDataset(nasreddin_corpus, tokenizer, SEQ_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"ğŸ“Š Dataset boyutu: {len(dataset):,} Ã¶rnek\")\n",
    "print(f\"ğŸ“Š Batch sayÄ±sÄ±: {len(dataloader)}\")\n",
    "\n",
    "# Ã–rnek batch\n",
    "x_sample, y_sample = next(iter(dataloader))\n",
    "print(f\"\\nğŸ“¦ Ã–rnek batch:\")\n",
    "print(f\"   x shape: {x_sample.shape}\")\n",
    "print(f\"   y shape: {y_sample.shape}\")\n",
    "print(f\"\\n   Ä°lk Ã¶rnek (ilk 50 karakter):\")\n",
    "print(f\"   Input:  '{tokenizer.decode(x_sample[0][:50].tolist())}'\")\n",
    "print(f\"   Target: '{tokenizer.decode(y_sample[0][:50].tolist())}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model Mimarisi\n",
    "\n",
    "Åimdi GPT'nin tÃ¼m bileÅŸenlerini sÄ±fÄ±rdan implement edeceÄŸiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model KonfigÃ¼rasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Model KonfigÃ¼rasyonu:\n",
      "   vocab_size:   56\n",
      "   max_seq_len:  128\n",
      "   d_model:      192\n",
      "   num_heads:    6\n",
      "   num_layers:   6\n",
      "   d_ff:         768\n",
      "   d_head:       32\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    \"\"\"GPT model konfigÃ¼rasyonu\"\"\"\n",
    "    vocab_size: int = 100        # Tokenizer'dan gelecek\n",
    "    max_seq_len: int = 128       # Maksimum sequence uzunluÄŸu\n",
    "    d_model: int = 192           # Embedding boyutu\n",
    "    num_heads: int = 6           # Attention head sayÄ±sÄ±\n",
    "    num_layers: int = 6          # Transformer block sayÄ±sÄ±\n",
    "    d_ff: int = 768              # FFN iÃ§ boyutu (4 * d_model)\n",
    "    dropout: float = 0.1         # Dropout oranÄ±\n",
    "    \n",
    "# Config oluÅŸtur\n",
    "config = GPTConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_seq_len=SEQ_LEN,\n",
    "    d_model=192,\n",
    "    num_heads=6,\n",
    "    num_layers=6,\n",
    "    d_ff=768,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ Model KonfigÃ¼rasyonu:\")\n",
    "print(f\"   vocab_size:   {config.vocab_size}\")\n",
    "print(f\"   max_seq_len:  {config.max_seq_len}\")\n",
    "print(f\"   d_model:      {config.d_model}\")\n",
    "print(f\"   num_heads:    {config.num_heads}\")\n",
    "print(f\"   num_layers:   {config.num_layers}\")\n",
    "print(f\"   d_ff:         {config.d_ff}\")\n",
    "print(f\"   d_head:       {config.d_model // config.num_heads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Causal Self-Attention\n",
    "\n",
    "GPT'nin kalbi! Her token sadece **Ã¶nceki tokenlere** bakabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CausalSelfAttention test:\n",
      "   Input:  torch.Size([2, 32, 192])\n",
      "   Output: torch.Size([2, 32, 192])\n"
     ]
    }
   ],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal (Masked) Self-Attention\n",
    "    \n",
    "    Her token sadece kendinden Ã¶nceki tokenlere attention uygulayabilir.\n",
    "    Bu, autoregressive generation iÃ§in gereklidir.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert config.d_model % config.num_heads == 0, \"d_model, num_heads'e bÃ¶lÃ¼nebilmeli!\"\n",
    "        \n",
    "        self.num_heads = config.num_heads\n",
    "        self.d_head = config.d_model // config.num_heads\n",
    "        self.d_model = config.d_model\n",
    "        \n",
    "        # Q, K, V projeksiyonlarÄ± tek bir linear layer'da (verimlilik iÃ§in)\n",
    "        self.qkv_proj = nn.Linear(config.d_model, 3 * config.d_model)\n",
    "        \n",
    "        # Output projeksiyonu\n",
    "        self.out_proj = nn.Linear(config.d_model, config.d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.out_dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "        # Causal mask: Ã¼st Ã¼Ã§gen matris (bakÄ±lmamasÄ± gereken pozisyonlar)\n",
    "        # Bu mask eÄŸitim sÄ±rasÄ±nda deÄŸiÅŸmez, buffer olarak kaydediyoruz\n",
    "        mask = torch.triu(\n",
    "            torch.ones(config.max_seq_len, config.max_seq_len), \n",
    "            diagonal=1\n",
    "        ).bool()\n",
    "        self.register_buffer('causal_mask', mask)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            output: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        # Q, K, V hesapla (tek seferde, sonra ayÄ±r)\n",
    "        qkv = self.qkv_proj(x)  # [B, T, 3*d_model]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)  # Her biri [B, T, d_model]\n",
    "        \n",
    "        # Head'lere ayÄ±r: [B, T, d_model] -> [B, num_heads, T, d_head]\n",
    "        q = q.view(B, T, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        k = k.view(B, T, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        \n",
    "        # Attention skorlarÄ±: Q @ K^T / sqrt(d_head)\n",
    "        # [B, heads, T, d_head] @ [B, heads, d_head, T] = [B, heads, T, T]\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "        \n",
    "        # Causal mask uygula (gelecek tokenler -inf olur)\n",
    "        scores = scores.masked_fill(self.causal_mask[:T, :T], float('-inf'))\n",
    "        \n",
    "        # Softmax (satÄ±r bazÄ±nda)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "        \n",
    "        # Attention output: weights @ V\n",
    "        # [B, heads, T, T] @ [B, heads, T, d_head] = [B, heads, T, d_head]\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Head'leri birleÅŸtir: [B, heads, T, d_head] -> [B, T, d_model]\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # Output projeksiyon\n",
    "        output = self.out_dropout(self.out_proj(attn_output))\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test\n",
    "attn = CausalSelfAttention(config)\n",
    "x_test = torch.randn(2, 32, config.d_model)\n",
    "out_test = attn(x_test)\n",
    "print(f\"âœ… CausalSelfAttention test:\")\n",
    "print(f\"   Input:  {x_test.shape}\")\n",
    "print(f\"   Output: {out_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feed-Forward Network (MLP)\n",
    "\n",
    "Ä°ki katmanlÄ± MLP. GELU aktivasyonu kullanÄ±yoruz (modern standart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MLP test: torch.Size([2, 32, 192]) -> torch.Size([2, 32, 192])\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network\n",
    "    \n",
    "    YapÄ±sÄ±: Linear -> GELU -> Linear -> Dropout\n",
    "    \n",
    "    d_model -> d_ff -> d_model (geniÅŸlet, daralt)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(config.d_model, config.d_ff)\n",
    "        self.fc2 = nn.Linear(config.d_ff, config.d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, d_model]\n",
    "        Returns:\n",
    "            output: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)       # [B, T, d_ff]\n",
    "        x = self.act(x)        # GELU aktivasyon\n",
    "        x = self.fc2(x)       # [B, T, d_model]\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "mlp = MLP(config)\n",
    "out_mlp = mlp(x_test)\n",
    "print(f\"âœ… MLP test: {x_test.shape} -> {out_mlp.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 GPT Block (Pre-LayerNorm)\n",
    "\n",
    "Modern GPT'ler **Pre-LN** kullanÄ±r: LayerNorm Ã¶nce gelir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPTBlock test: torch.Size([2, 32, 192]) -> torch.Size([2, 32, 192])\n"
     ]
    }
   ],
   "source": [
    "class GPTBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Tek bir GPT Transformer bloÄŸu (Pre-LayerNorm versiyonu)\n",
    "    \n",
    "    YapÄ±sÄ±:\n",
    "    x -> LN -> Attention -> + -> LN -> MLP -> +\n",
    "    |__________________________|            |\n",
    "                               |____________|\n",
    "            (residual connections)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(config.d_model)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.d_model)\n",
    "        self.mlp = MLP(config)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pre-LN: LayerNorm sublayer'dan Ã–NCE uygulanÄ±r\n",
    "        \n",
    "        Bu, residual path'i temiz tutar ve gradient flow'u iyileÅŸtirir.\n",
    "        \"\"\"\n",
    "        # Attention block with residual\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        \n",
    "        # MLP block with residual  \n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test\n",
    "block = GPTBlock(config)\n",
    "out_block = block(x_test)\n",
    "print(f\"âœ… GPTBlock test: {x_test.shape} -> {out_block.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Tam GPT Modeli\n",
    "\n",
    "TÃ¼m parÃ§alarÄ± birleÅŸtiriyoruz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Mini GPT Modeli OluÅŸturuldu!\n",
      "\n",
      "ğŸ“Š Model Ä°statistikleri:\n",
      "   Toplam parametre: 2,704,896\n",
      "   YaklaÅŸÄ±k: 2.70M parametre\n",
      "\n",
      "âœ… Forward pass test:\n",
      "   Input shape:  torch.Size([2, 32])\n",
      "   Logits shape: torch.Size([2, 32, 56])\n",
      "   Loss: 4.0638\n"
     ]
    }
   ],
   "source": [
    "class MiniGPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Mini GPT - Decoder-Only Transformer\n",
    "    \n",
    "    BileÅŸenler:\n",
    "    1. Token Embedding\n",
    "    2. Position Embedding (learned)\n",
    "    3. N x GPT Block\n",
    "    4. Final LayerNorm\n",
    "    5. Output Head (weight tying ile)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Token embedding: vocab_size -> d_model\n",
    "        self.token_emb = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        \n",
    "        # Position embedding (learned, sinusoidal deÄŸil)\n",
    "        self.pos_emb = nn.Embedding(config.max_seq_len, config.d_model)\n",
    "        \n",
    "        # Embedding dropout\n",
    "        self.drop = nn.Dropout(config.dropout)\n",
    "        \n",
    "        # GPT blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            GPTBlock(config) for _ in range(config.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final LayerNorm\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        \n",
    "        # Output head: d_model -> vocab_size\n",
    "        self.head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "        \n",
    "        # â­ Weight Tying: embedding ve output head aÄŸÄ±rlÄ±klarÄ±nÄ± paylaÅŸ\n",
    "        # Bu hem parametre tasarrufu saÄŸlar hem de performansÄ± artÄ±rÄ±r\n",
    "        self.head.weight = self.token_emb.weight\n",
    "        \n",
    "        # AÄŸÄ±rlÄ±k baÅŸlatma\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"AÄŸÄ±rlÄ±klarÄ± GPT-2 tarzÄ± baÅŸlat\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    def forward(self, idx, targets=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx: Token ID'leri [batch_size, seq_len]\n",
    "            targets: Hedef token ID'leri (eÄŸitim iÃ§in) [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            logits: [batch_size, seq_len, vocab_size]\n",
    "            loss: Cross-entropy loss (targets verilmiÅŸse)\n",
    "        \"\"\"\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # Token embedding\n",
    "        tok_emb = self.token_emb(idx)  # [B, T, d_model]\n",
    "        \n",
    "        # Position embedding\n",
    "        positions = torch.arange(T, device=idx.device)  # [T]\n",
    "        pos_emb = self.pos_emb(positions)  # [T, d_model]\n",
    "        \n",
    "        # Embedding'leri topla\n",
    "        x = self.drop(tok_emb + pos_emb)  # [B, T, d_model]\n",
    "        \n",
    "        # GPT blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        # Final LayerNorm\n",
    "        x = self.ln_f(x)  # [B, T, d_model]\n",
    "        \n",
    "        # Output projection (logits)\n",
    "        logits = self.head(x)  # [B, T, vocab_size]\n",
    "        \n",
    "        # Loss hesapla (eÄŸer targets verilmiÅŸse)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),  # [B*T, vocab_size]\n",
    "                targets.view(-1)                    # [B*T]\n",
    "            )\n",
    "            \n",
    "        return logits, loss\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        \"\"\"Toplam parametre sayÄ±sÄ± (weight tying hariÃ§)\"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        # Weight tying nedeniyle embedding'i bir kez sayÄ±yoruz\n",
    "        return n_params\n",
    "\n",
    "# Model oluÅŸtur\n",
    "model = MiniGPT(config).to(device)\n",
    "\n",
    "print(\"ğŸ¤– Mini GPT Modeli OluÅŸturuldu!\")\n",
    "print(f\"\\nğŸ“Š Model Ä°statistikleri:\")\n",
    "print(f\"   Toplam parametre: {model.get_num_params():,}\")\n",
    "print(f\"   YaklaÅŸÄ±k: {model.get_num_params() / 1e6:.2f}M parametre\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randint(0, config.vocab_size, (2, 32)).to(device)\n",
    "test_target = torch.randint(0, config.vocab_size, (2, 32)).to(device)\n",
    "logits, loss = model(test_input, test_target)\n",
    "\n",
    "print(f\"\\nâœ… Forward pass test:\")\n",
    "print(f\"   Input shape:  {test_input.shape}\")\n",
    "print(f\"   Logits shape: {logits.shape}\")\n",
    "print(f\"   Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. EÄŸitim\n",
    "\n",
    "Åimdi modelimizi Nasreddin Hoca fÄ±kralarÄ±yla eÄŸiteceÄŸiz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ EÄŸitim AyarlarÄ±:\n",
      "   Learning rate: 0.0003\n",
      "   Epochs: 100\n",
      "   Batch size: 32\n",
      "   Optimizer: AdamW\n"
     ]
    }
   ],
   "source": [
    "# EÄŸitim parametreleri\n",
    "LEARNING_RATE = 3e-4\n",
    "NUM_EPOCHS = 100\n",
    "EVAL_INTERVAL = 10\n",
    "\n",
    "# Optimizer (AdamW - weight decay ile)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler (cosine annealing)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=NUM_EPOCHS, eta_min=LEARNING_RATE / 10\n",
    ")\n",
    "\n",
    "print(f\"âš™ï¸ EÄŸitim AyarlarÄ±:\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Optimizer: AdamW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    \"\"\"Tek bir epoch eÄŸitim\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, loss = model(x, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (stabilite iÃ§in)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    return total_loss / num_batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"Model deÄŸerlendirme\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits, loss = model(x, y)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ EÄŸitim baÅŸlÄ±yor...\n",
      "\n",
      "Epoch   1/100 | Loss: 2.3525 | Perplexity: 10.51 | LR: 3.00e-04\n",
      "Epoch  10/100 | Loss: 0.1042 | Perplexity: 1.11 | LR: 2.93e-04\n",
      "Epoch  20/100 | Loss: 0.0703 | Perplexity: 1.07 | LR: 2.74e-04\n",
      "Epoch  30/100 | Loss: 0.0607 | Perplexity: 1.06 | LR: 2.44e-04\n",
      "Epoch  40/100 | Loss: 0.0551 | Perplexity: 1.06 | LR: 2.07e-04\n",
      "Epoch  50/100 | Loss: 0.0521 | Perplexity: 1.05 | LR: 1.65e-04\n",
      "Epoch  60/100 | Loss: 0.0496 | Perplexity: 1.05 | LR: 1.23e-04\n",
      "Epoch  70/100 | Loss: 0.0480 | Perplexity: 1.05 | LR: 8.56e-05\n",
      "Epoch  80/100 | Loss: 0.0467 | Perplexity: 1.05 | LR: 5.58e-05\n",
      "Epoch  90/100 | Loss: 0.0457 | Perplexity: 1.05 | LR: 3.66e-05\n",
      "Epoch 100/100 | Loss: 0.0452 | Perplexity: 1.05 | LR: 3.00e-05\n",
      "\n",
      "âœ… EÄŸitim tamamlandÄ±!\n",
      "   En iyi loss: 0.0452\n",
      "   En iyi perplexity: 1.05\n"
     ]
    }
   ],
   "source": [
    "# EÄŸitim dÃ¶ngÃ¼sÃ¼\n",
    "print(\"ğŸš€ EÄŸitim baÅŸlÄ±yor...\\n\")\n",
    "\n",
    "train_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    # EÄŸitim\n",
    "    train_loss = train_epoch(model, dataloader, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Learning rate gÃ¼ncelle\n",
    "    scheduler.step()\n",
    "    \n",
    "    # En iyi modeli kaydet\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    # Ä°lerleme raporu\n",
    "    if epoch % EVAL_INTERVAL == 0 or epoch == 1:\n",
    "        perplexity = math.exp(train_loss)\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch:3d}/{NUM_EPOCHS} | Loss: {train_loss:.4f} | Perplexity: {perplexity:.2f} | LR: {lr:.2e}\")\n",
    "\n",
    "print(f\"\\nâœ… EÄŸitim tamamlandÄ±!\")\n",
    "print(f\"   En iyi loss: {best_loss:.4f}\")\n",
    "print(f\"   En iyi perplexity: {math.exp(best_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EÄŸitim grafiÄŸi\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, 'b-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('EÄŸitim Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "perplexities = [math.exp(l) for l in train_losses]\n",
    "plt.plot(perplexities, 'r-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Metin Ãœretimi\n",
    "\n",
    "FarklÄ± sampling stratejileri ile metin Ã¼retimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generate fonksiyonu tanÄ±mlandÄ±\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model, \n",
    "    tokenizer,\n",
    "    prompt=\"Nasreddin Hoca\",\n",
    "    max_tokens=200,\n",
    "    temperature=1.0,\n",
    "    top_k=None,\n",
    "    top_p=None,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Metin Ã¼retimi (autoregressive generation)\n",
    "    \n",
    "    Args:\n",
    "        model: EÄŸitilmiÅŸ GPT modeli\n",
    "        tokenizer: Tokenizer\n",
    "        prompt: BaÅŸlangÄ±Ã§ metni\n",
    "        max_tokens: Ãœretilecek maksimum token sayÄ±sÄ±\n",
    "        temperature: Sampling temperature (1.0 = normal)\n",
    "        top_k: Top-k sampling (None = kapalÄ±)\n",
    "        top_p: Nucleus sampling (None = kapalÄ±)\n",
    "        device: Cihaz\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Prompt'u tokenize et\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    \n",
    "    # Token token Ã¼ret\n",
    "    for _ in range(max_tokens):\n",
    "        # Maksimum context uzunluÄŸunu kontrol et\n",
    "        tokens_cond = tokens[:, -model.config.max_seq_len:]\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, _ = model(tokens_cond)\n",
    "        \n",
    "        # Son pozisyonun logits'i\n",
    "        logits = logits[:, -1, :]  # [1, vocab_size]\n",
    "        \n",
    "        # Temperature uygula\n",
    "        logits = logits / temperature\n",
    "        \n",
    "        # Top-k sampling\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            logits[logits < v[:, [-1]]] = float('-inf')\n",
    "            \n",
    "        # Top-p (nucleus) sampling\n",
    "        if top_p is not None:\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumsum_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "            \n",
    "            # p'yi aÅŸan tokenleri maskele\n",
    "            sorted_indices_to_remove = cumsum_probs > top_p\n",
    "            sorted_indices_to_remove[:, 1:] = sorted_indices_to_remove[:, :-1].clone()\n",
    "            sorted_indices_to_remove[:, 0] = False\n",
    "            \n",
    "            indices_to_remove = sorted_indices_to_remove.scatter(\n",
    "                1, sorted_indices, sorted_indices_to_remove\n",
    "            )\n",
    "            logits[indices_to_remove] = float('-inf')\n",
    "        \n",
    "        # OlasÄ±lÄ±klarÄ± hesapla\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Ã–rnekle\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        # Token'Ä± ekle\n",
    "        tokens = torch.cat([tokens, next_token], dim=1)\n",
    "        \n",
    "    # Decode et\n",
    "    generated_text = tokenizer.decode(tokens[0].tolist())\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "print(\"âœ… Generate fonksiyonu tanÄ±mlandÄ±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ Metin Ãœretimi Ã–rnekleri\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# En iyi modeli yÃ¼kle\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "print(\"ğŸ­ Metin Ãœretimi Ã–rnekleri\\n\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Ã–rnek 1: Greedy-like (temperature=0.3)\n",
      "------------------------------------------------------------\n",
      "Nasreddin Hoca bir gÃ¼n Ã§arÅŸÄ±da gezerken birisi ona bir tokat atmÄ±ÅŸ. Hoca adama bakmÄ±ÅŸ ve demiÅŸ: \"Ã–zÃ¼r dilerim, sizi tanÄ±yamadÄ±m.\" Adam ÅŸaÅŸÄ±rmÄ±ÅŸ: \"Ben sana tokat attÄ±m, sen \n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 1: Greedy (temperature Ã§ok dÃ¼ÅŸÃ¼k)\n",
    "print(\"\\nğŸ“ Ã–rnek 1: Greedy-like (temperature=0.3)\")\n",
    "print(\"-\" * 60)\n",
    "text = generate(\n",
    "    model, tokenizer, \n",
    "    prompt=\"Nasreddin Hoca bir gÃ¼n\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.3,\n",
    "    device=device\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Ã–rnek 2: Normal sampling (temperature=0.8)\n",
      "------------------------------------------------------------\n",
      "Hoca pazara gitmiÅŸ. SatÄ±cÄ± sormuÅŸ: \"Hoca bu kabaÄŸÄ± kaÃ§a alÄ±rsÄ±n?\" Hoca: \"BeÅŸ akÃ§eye alÄ±rÄ±m.\" demiÅŸ. SatÄ±cÄ±: \"On akÃ§e ister.\" demiÅŸ. Hoca dÃ¼ÅŸÃ¼nmÃ¼ÅŸ ve demiÅŸ ki: \"Ben beÅŸ \n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 2: Normal sampling\n",
    "print(\"\\nğŸ“ Ã–rnek 2: Normal sampling (temperature=0.8)\")\n",
    "print(\"-\" * 60)\n",
    "text = generate(\n",
    "    model, tokenizer,\n",
    "    prompt=\"Hoca pazara gitmiÅŸ\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.8,\n",
    "    device=device\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Ã–rnek 3: Top-k sampling (k=40, temperature=0.9)\n",
      "------------------------------------------------------------\n",
      "Bir gÃ¼n HocanÄ±n evine hÄ±rsÄ±z girmiÅŸ. Hoca uyanmÄ±ÅŸ ama sesini Ã§Ä±karmamÄ±ÅŸ. HÄ±rsÄ±z her yeri aramÄ±ÅŸ ama bir ÅŸey bulamamÄ±ÅŸ. Tam giderken Hoca arkasÄ±ndan seslenmiÅŸ: \"Ev\n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 3: Top-k sampling\n",
    "print(\"\\nğŸ“ Ã–rnek 3: Top-k sampling (k=40, temperature=0.9)\")\n",
    "print(\"-\" * 60)\n",
    "text = generate(\n",
    "    model, tokenizer,\n",
    "    prompt=\"Bir gÃ¼n Hoca\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.9,\n",
    "    top_k=40,\n",
    "    device=device\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Ã–rnek 4: Nucleus sampling (p=0.9, temperature=0.8)\n",
      "------------------------------------------------------------\n",
      "KomÅŸusu Hocaya sormuÅŸ: \"KapÄ±da dilenci var, ekmek istiyor.\" Hoca: \"SÃ¶yle aÅŸaÄŸÄ± insin.\" demiÅŸ. Dilenci aÅŸaÄŸÄ± inmiÅŸ. Hoca yine: \"SÃ¶yle biraz daha aÅŸaÄŸÄ± insin.\" demiÅŸ. Dilenc\n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek 4: Nucleus (top-p) sampling\n",
    "print(\"\\nğŸ“ Ã–rnek 4: Nucleus sampling (p=0.9, temperature=0.8)\")\n",
    "print(\"-\" * 60)\n",
    "text = generate(\n",
    "    model, tokenizer,\n",
    "    prompt=\"KomÅŸusu Hocaya sormuÅŸ\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.8,\n",
    "    top_p=0.9,\n",
    "    device=device\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ® Kendi prompt'unuzu deneyin!\n",
      "============================================================\n",
      "\n",
      "Prompt: 'Hoca eÅŸeÄŸini'\n",
      "------------------------------------------------------------\n",
      "Hoca eÅŸeÄŸini kaybetmiÅŸ. Her yerde aramÄ±ÅŸ bulamamÄ±ÅŸ. Sonunda gÃ¶zleri dolarak dua etmeye baÅŸlamÄ±ÅŸ: \"Ya Rabbi! EÅŸeÄŸimi buldur. Bulduran kiÅŸiye eÅŸeÄŸi vereceÄŸim.\" YanÄ±ndakiler sormuÅŸ: \"Hoca, eÅŸeÄŸi bulana verirsen sana\n"
     ]
    }
   ],
   "source": [
    "# Ä°nteraktif deneme\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ® Kendi prompt'unuzu deneyin!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "custom_prompt = \"Hoca eÅŸeÄŸini\"  # Ä°stediÄŸiniz prompt'u yazÄ±n\n",
    "\n",
    "text = generate(\n",
    "    model, tokenizer,\n",
    "    prompt=custom_prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    device=device\n",
    ")\n",
    "print(f\"\\nPrompt: '{custom_prompt}'\")\n",
    "print(\"-\" * 60)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. SonuÃ§lar ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š MODEL Ã–ZETÄ°\n",
      "============================================================\n",
      "\n",
      "ğŸ—ï¸ Mimari:\n",
      "   Tip: Decoder-Only Transformer (GPT-style)\n",
      "   Layer sayÄ±sÄ±: 6\n",
      "   Head sayÄ±sÄ±: 6\n",
      "   d_model: 192\n",
      "   d_ff: 768\n",
      "   Parametre sayÄ±sÄ±: 2,704,896\n",
      "\n",
      "ğŸ“š Veri:\n",
      "   Dataset: Nasreddin Hoca fÄ±kralarÄ±\n",
      "   Corpus boyutu: 5,339 karakter\n",
      "   Vocab boyutu: 56\n",
      "   Sequence uzunluÄŸu: 128\n",
      "\n",
      "ğŸ“ˆ EÄŸitim:\n",
      "   Final loss: 0.0452\n",
      "   Final perplexity: 1.05\n",
      "   En iyi loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "# Model Ã¶zeti\n",
    "print(\"ğŸ“Š MODEL Ã–ZETÄ°\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ—ï¸ Mimari:\")\n",
    "print(f\"   Tip: Decoder-Only Transformer (GPT-style)\")\n",
    "print(f\"   Layer sayÄ±sÄ±: {config.num_layers}\")\n",
    "print(f\"   Head sayÄ±sÄ±: {config.num_heads}\")\n",
    "print(f\"   d_model: {config.d_model}\")\n",
    "print(f\"   d_ff: {config.d_ff}\")\n",
    "print(f\"   Parametre sayÄ±sÄ±: {model.get_num_params():,}\")\n",
    "\n",
    "print(f\"\\nğŸ“š Veri:\")\n",
    "print(f\"   Dataset: Nasreddin Hoca fÄ±kralarÄ±\")\n",
    "print(f\"   Corpus boyutu: {len(nasreddin_corpus):,} karakter\")\n",
    "print(f\"   Vocab boyutu: {tokenizer.vocab_size}\")\n",
    "print(f\"   Sequence uzunluÄŸu: {SEQ_LEN}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ EÄŸitim:\")\n",
    "print(f\"   Final loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"   Final perplexity: {math.exp(train_losses[-1]):.2f}\")\n",
    "print(f\"   En iyi loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Ã–nemli GÃ¶zlemler\n",
    "\n",
    "1. **KÃ¼Ã§Ã¼k dataset = Overfitting**: Model ezberlemeye baÅŸlayabilir. Daha fazla veri ile daha iyi sonuÃ§ alÄ±nÄ±r.\n",
    "\n",
    "2. **Character-level vs Subword**: BPE tokenization daha verimli olurdu, ama char-level anlaÅŸÄ±lmasÄ± kolay.\n",
    "\n",
    "3. **Temperature etkisi**:\n",
    "   - DÃ¼ÅŸÃ¼k (0.3): Tekrarlayan, gÃ¼venli Ã§Ä±ktÄ±lar\n",
    "   - Normal (0.7-0.9): Dengeli ve okunabilir\n",
    "   - YÃ¼ksek (>1.5): YaratÄ±cÄ± ama anlamsÄ±zlaÅŸabilir\n",
    "\n",
    "4. **Top-p vs Top-k**:\n",
    "   - Top-p dinamik (daÄŸÄ±lÄ±ma gÃ¶re ayarlanÄ±r)\n",
    "   - Top-k sabit (her zaman k token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ SonuÃ§\n",
    "\n",
    "Bu notebook'ta sÄ±fÄ±rdan bir GPT modeli inÅŸa ettik:\n",
    "\n",
    "âœ… Causal Self-Attention implementasyonu  \n",
    "âœ… Pre-LayerNorm GPT Block  \n",
    "âœ… Weight Tying  \n",
    "âœ… Ã‡eÅŸitli sampling stratejileri  \n",
    "âœ… Nasreddin Hoca fÄ±kralarÄ±yla eÄŸitim  \n",
    "\n",
    "### ğŸ“š Sonraki AdÄ±mlar\n",
    "\n",
    "- Daha bÃ¼yÃ¼k dataset ile eÄŸitim\n",
    "- BPE tokenization ekleme\n",
    "- Flash Attention optimizasyonu\n",
    "- Fine-tuning denemeler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
